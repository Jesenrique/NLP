{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['que', 'dia', 'es', 'hoy']\n","['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","['martes', 'muchas', 'gracias']\n","Terminos no repetidos en el corpus: {'muchas', 'dia', 'gracias', 'es', 'que', 'de', 'el', 'hoy', 'martes'}\n"]}],"source":["vector=[]\n","i=0\n","for documento in corpus:\n","    for termino in documento.split():\n","        vector.append(termino)\n","    print(documento.split())\n","\n","vector=set(vector)\n","print(f\"Terminos no repetidos en el corpus: {vector}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["def oneHotEnconder (vector,documento):\n","    listOneHot=[]\n","    #recorre todos los terminos del vector\n","    for termino in vector:\n","        #busca el termino en el documento o texto\n","        if termino in documento:\n","            listOneHot.append(1)\n","        else:\n","            listOneHot.append(0)\n","    return listOneHot"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["listOnehot=[]\n","for i in corpus:\n","    listOnehot.append(oneHotEnconder(vector,i)) "]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0, 1, 0, 1, 1, 0, 0, 1, 0],\n","       [0, 1, 0, 1, 0, 1, 1, 1, 1],\n","       [1, 0, 1, 1, 0, 0, 0, 0, 1]])"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["listOnehot=np.array(listOnehot)\n","listOnehot"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[],"source":["def TF (vector, documento):\n","  listFrecuency=[]\n","  for i in vector:\n","    counter=0\n","    #busca cada termino i en los j terminos del documento\n","    for j in documento:\n","      if i==j:\n","        counter=counter+1\n","    listFrecuency.append(counter)\n","  return listFrecuency"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"data":{"text/plain":["[[0, 1, 0, 1, 1, 0, 0, 1, 0],\n"," [0, 1, 0, 1, 0, 1, 1, 1, 2],\n"," [1, 0, 1, 0, 0, 0, 0, 0, 1]]"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["listTF=[]\n","\n","for documento in corpus:\n","    listTF.append(TF(vector,documento.split()))\n","\n","listTF"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["\n","def IDF (corpus, vector):\n","  listCounter=[]\n","  for termino in vector:\n","    counter=0\n","    # busca si el termino del vector se encuentra dentro de cada documento del corpus\n","    for documento in corpus:\n","      #si el termino esta aumenta el contador\n","      if termino in documento.split():\n","        counter=counter+1\n","    #Se calcula el factor IDF    \n","    N=len(corpus)\n","    listCounter.append(np.log(N/counter))\n","  return listCounter"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"data":{"text/plain":["[1.0986122886681098,\n"," 0.4054651081081644,\n"," 1.0986122886681098,\n"," 0.4054651081081644,\n"," 1.0986122886681098,\n"," 1.0986122886681098,\n"," 1.0986122886681098,\n"," 0.4054651081081644,\n"," 0.4054651081081644]"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["idf=IDF(corpus,vector)\n","idf"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.        , 0.40546511, 0.        , 0.40546511, 1.09861229,\n","        0.        , 0.        , 0.40546511, 0.        ],\n","       [0.        , 0.40546511, 0.        , 0.40546511, 0.        ,\n","        1.09861229, 1.09861229, 0.40546511, 0.81093022],\n","       [1.09861229, 0.        , 1.09861229, 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.40546511]])"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["#multiplico el TF calculado anteriormente y lo multiplico por el factor IDF\n","tf_idf=np.array(listTF)*idf\n","tf_idf"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["from itertools import combinations\n","\n","#creo un diccionario con el indice es key y el value es el valor vectorizado de la frase\n","frases={idx:n_vector for idx,n_vector in enumerate (tf_idf)}\n","\n","# Generar todas las combinaciones de 2 elementos con cada key\n","combinaciones = list(combinations(frases, 2))\n","\n","#Aplico la funcion de similitud coseno a cada combinación \n","scoreCos=[]\n","for i in combinaciones:\n","    scoreCos.append(cosine_similarity(frases[i[0]],frases[i[1]]))\n","\n","#creo un diccionario donde la key es la similitud coseno y el value es la combinación\n","#de cada frase\n","similitudes=dict(zip(scoreCos,combinaciones))\n","\n","#ordeno las keys de mayor a menor\n","keys_ordenados = sorted(similitudes.keys(),reverse=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"text/plain":["[0.20034190268098706, 0.10845711727883084, 0.0]"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["keys_ordenados"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
